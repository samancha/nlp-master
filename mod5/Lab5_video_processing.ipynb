{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samancha/nlp-master/blob/main/mod5/Lab5_video_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "metadata": {
        "id": "Jpbjr-XCWH-H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KRIigyRyQAc0"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('/content/pedestrians.avi')\n",
        "video_fps = cap.get(cv2.CAP_PROP_FPS),\n",
        "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "\n",
        "out_video_path = '/content/filtered_video.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
        "writer = cv2.VideoWriter(out_video_path, apiPreference=0, fourcc=fourcc,\n",
        "                     fps=video_fps[0], frameSize=(int(width), int(height)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqJwJfCaMHmY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "OPENCV_MAJOR_VERSION = int(cv2.__version__.split('.')[0])\n",
        "\n",
        "class Pedestrian():\n",
        "    \"\"\"A tracked pedestrian with a state including an ID, tracking\n",
        "    window, histogram, and Kalman filter.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, id, hsv_frame, track_window):\n",
        "\n",
        "        self.id = id\n",
        "\n",
        "        self.track_window = track_window\n",
        "        self.term_crit = \\\n",
        "            (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 10, 1)\n",
        "\n",
        "        # Initialize the histogram.\n",
        "        x, y, w, h = track_window\n",
        "        roi = hsv_frame[y:y+h, x:x+w]\n",
        "        roi_hist = cv2.calcHist([roi], [0], None, [16], [0, 180])\n",
        "        self.roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255,\n",
        "                                      cv2.NORM_MINMAX)\n",
        "\n",
        "        # Initialize the Kalman filter.\n",
        "        self.kalman = cv2.KalmanFilter(4, 2)\n",
        "        self.kalman.measurementMatrix = np.array(\n",
        "            [[1, 0, 0, 0],\n",
        "             [0, 1, 0, 0]], np.float32)\n",
        "        self.kalman.transitionMatrix = np.array(\n",
        "            [[1, 0, 1, 0],\n",
        "             [0, 1, 0, 1],\n",
        "             [0, 0, 1, 0],\n",
        "             [0, 0, 0, 1]], np.float32)\n",
        "        self.kalman.processNoiseCov = np.array(\n",
        "            [[1, 0, 0, 0],\n",
        "             [0, 1, 0, 0],\n",
        "             [0, 0, 1, 0],\n",
        "             [0, 0, 0, 1]], np.float32) * 0.03\n",
        "        cx = x+w/2\n",
        "        cy = y+h/2\n",
        "        self.kalman.statePre = np.array(\n",
        "            [[cx], [cy], [0], [0]], np.float32)\n",
        "        self.kalman.statePost = np.array(\n",
        "            [[cx], [cy], [0], [0]], np.float32)\n",
        "\n",
        "    def update(self, frame, hsv_frame):\n",
        "\n",
        "        back_proj = cv2.calcBackProject(\n",
        "            [hsv_frame], [0], self.roi_hist, [0, 180], 1)\n",
        "\n",
        "        ret, self.track_window = cv2.meanShift(\n",
        "            back_proj, self.track_window, self.term_crit)\n",
        "        x, y, w, h = self.track_window\n",
        "        center = np.array([x+w/2, y+h/2], np.float32)\n",
        "\n",
        "        prediction = self.kalman.predict()\n",
        "        estimate = self.kalman.correct(center)\n",
        "        center_offset = estimate[:,0][:2] - center\n",
        "        self.track_window = (x + int(center_offset[0]),\n",
        "                             y + int(center_offset[1]), w, h)\n",
        "        x, y, w, h = self.track_window\n",
        "\n",
        "        # Draw the predicted center position as a blue circle.\n",
        "        cv2.circle(frame, (int(prediction[0]), int(prediction[1])),\n",
        "                   4, (255, 0, 0), -1)\n",
        "\n",
        "        # Draw the corrected tracking window as a cyan rectangle.\n",
        "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 2)\n",
        "\n",
        "        # Draw the ID above the rectangle in blue text.\n",
        "        cv2.putText(frame, 'ID: %d' % self.id, (x, y-5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0),\n",
        "                    1, cv2.LINE_AA)\n",
        "\n",
        "def main():\n",
        "\n",
        "    cap = cv2.VideoCapture('/content/pedestrians.avi')\n",
        "\n",
        "    total_video = []\n",
        "\n",
        "    # Create the KNN background subtractor.\n",
        "    bg_subtractor = cv2.createBackgroundSubtractorKNN()\n",
        "    history_length = 20\n",
        "    bg_subtractor.setHistory(history_length)\n",
        "\n",
        "    erode_kernel = cv2.getStructuringElement(\n",
        "        cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    dilate_kernel = cv2.getStructuringElement(\n",
        "        cv2.MORPH_ELLIPSE, (8, 3))\n",
        "\n",
        "    pedestrians = []\n",
        "    num_history_frames_populated = 0\n",
        "    while True:\n",
        "        grabbed, frame = cap.read()\n",
        "        if (grabbed is False):\n",
        "            break\n",
        "\n",
        "        # Apply the KNN background subtractor.\n",
        "        fg_mask = bg_subtractor.apply(frame)\n",
        "\n",
        "        # Let the background subtractor build up a history.\n",
        "        if num_history_frames_populated < history_length:\n",
        "            num_history_frames_populated += 1\n",
        "            continue\n",
        "\n",
        "        # Create the thresholded image.\n",
        "        _, thresh = cv2.threshold(fg_mask, 127, 255,\n",
        "                                  cv2.THRESH_BINARY)\n",
        "        cv2.erode(thresh, erode_kernel, thresh, iterations=2)\n",
        "        cv2.dilate(thresh, dilate_kernel, thresh, iterations=2)\n",
        "\n",
        "        # Detect contours in the thresholded image.\n",
        "        if OPENCV_MAJOR_VERSION >= 4:\n",
        "            # OpenCV 4 or a later version is being used.\n",
        "            contours, hier = cv2.findContours(\n",
        "                thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        else:\n",
        "            # OpenCV 3 or an earlier version is being used.\n",
        "            # cv2.findContours has an extra return value.\n",
        "            # The extra return value is the thresholded image, which\n",
        "            # is unchanged, so we can ignore it.\n",
        "            _, contours, hier = cv2.findContours(\n",
        "                thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # Draw green rectangles around large contours.\n",
        "        # Also, if no pedestrians are being tracked yet, create some.\n",
        "        should_initialize_pedestrians = len(pedestrians) == 0\n",
        "        id = 0\n",
        "        for c in contours:\n",
        "            if cv2.contourArea(c) > 500:\n",
        "                (x, y, w, h) = cv2.boundingRect(c)\n",
        "                cv2.rectangle(frame, (x, y), (x+w, y+h),\n",
        "                              (0, 255, 0), 1)\n",
        "                if should_initialize_pedestrians:\n",
        "                    pedestrians.append(\n",
        "                        Pedestrian(id, hsv_frame,\n",
        "                                   (x, y, w, h)))\n",
        "            id += 1\n",
        "\n",
        "        # Update the tracking of each pedestrian.\n",
        "        for pedestrian in pedestrians:\n",
        "            pedestrian.update(frame, hsv_frame)\n",
        "\n",
        "        #cv2_imshow(frame)\n",
        "\n",
        "        #total_video.append(frame)\n",
        "        writer.write(frame)\n",
        "        k = cv2.waitKey(110)\n",
        "        if k == 27:  # Escape\n",
        "            break\n",
        "\n",
        "        #return(frame)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    writer.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URDZbdAcRh9z"
      },
      "outputs": [],
      "source": [
        "# Play the result\n",
        "video_path = '/content/filtered_video.mp4'\n",
        "\n",
        "mp4 = open(video_path,'rb').read()\n",
        "decoded_vid = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f'<video width=400 controls><source src={decoded_vid} type=\"video/mp4\"></video>')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}