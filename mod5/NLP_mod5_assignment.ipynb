{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samancha/nlp-master/blob/main/mod5/NLP_mod5_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZsoeEsqsVSq"
      },
      "source": [
        "# Data loading and preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For some context, I've download the data and pushed it into my google drive or locally. I've developed both in colab and vs code, while pushing the notebook back and forth when doing heavier computation commands."
      ],
      "metadata": {
        "id": "A1S1VO9YOqfa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uqx40czYv3O9",
        "outputId": "151fef93-b10e-41cd-95ea-7b805dc908d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJVxC6nSskUO"
      },
      "outputs": [],
      "source": [
        "! pip install transformers[torch]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb7aPObZsVSs"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, TrainingArguments, Trainer\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import torch\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "# Download the stopwords and tokenizer from nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "seed_val = 42\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "print(\"gpu avail: \", torch.cuda.is_available())\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing data is essentially to getting optimal model results. I used a modular approach and created a function to process each \"review\" row in the data. I first began with tokenizing the text which better helped identify sets of words and distinguish puntuation more properly. I also lowered all the words and removing the following: punctuation, stopwords, and duplicate words. I was hesitant with removing duplicate words, but I was satisfied with the results I was able to produce.  "
      ],
      "metadata": {
        "id": "byv4aCnRO-7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nXngAcrcUv4O"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Convert words to lowercase\n",
        "    words = [word.lower() for word in words]\n",
        "\n",
        "    # Remove punctuation from words\n",
        "    words = [word for word in words if word.isalnum()]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Remove duplicate words\n",
        "    unique_words = list(dict.fromkeys(words))\n",
        "\n",
        "    # Join the words back into a string\n",
        "    text = ' '.join(unique_words)\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created a label column based on the sentiment, so that it would be friendlier to process. I also added the processed reviews to the data frame for future usage."
      ],
      "metadata": {
        "id": "TX5PU6X1PSnz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SIWM-LQcsVSt",
        "outputId": "5b78a07a-17f8-4171-fb7f-c7da49572185"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              review sentiment  label  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive      1   \n",
              "1  A wonderful little production. <br /><br />The...  positive      1   \n",
              "2  I thought this was a wonderful way to spend ti...  positive      1   \n",
              "3  Basically there's a family where a little boy ...  negative      0   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1   \n",
              "\n",
              "                                    processed_review  \n",
              "0  one reviewers mentioned watching 1 oz episode ...  \n",
              "1  wonderful little production br filming techniq...  \n",
              "2  thought wonderful way spend time hot summer we...  \n",
              "3  basically family little boy jake thinks zombie...  \n",
              "4  petter mattei love time money visually stunnin...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d295913e-4a4d-4dcf-9eda-40c8fbce9d4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "      <th>processed_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>wonderful little production br filming techniq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>basically family little boy jake thinks zombie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d295913e-4a4d-4dcf-9eda-40c8fbce9d4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d295913e-4a4d-4dcf-9eda-40c8fbce9d4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d295913e-4a4d-4dcf-9eda-40c8fbce9d4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60e7c318-2b24-458f-9c94-3f082c3d4bc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60e7c318-2b24-458f-9c94-3f082c3d4bc1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60e7c318-2b24-458f-9c94-3f082c3d4bc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/archive.zip')\n",
        "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "df['processed_review'] = df['review'].apply(preprocess_text)\n",
        "df.reset_index(drop=True)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY0UcONisVSv"
      },
      "source": [
        "# Text tokenization and conversion to BERT input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fhxUrhi9sVSv"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phC7hD2m1R0H"
      },
      "source": [
        "Initializing processed reviews as inputs and associated labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwJi4x1sgYKX",
        "outputId": "0a7bc247-464a-4998-95ce-41cafadaeef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size  50000\n"
          ]
        }
      ],
      "source": [
        "inputs = df.processed_review.values\n",
        "labels = df.label.values\n",
        "print(\"Train data size \", len(inputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXiDVR9X_zWx",
        "outputId": "3a520943-232e-42ee-e89b-bfff577262fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  one reviewers mentioned watching 1 oz episode hooked right exactly happened br first thing struck brutality unflinching scenes violence set word go trust show faint hearted timid pulls punches regards drugs sex hardcore classic use called nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far would say main appeal due fact goes shows dare forget pretty pictures painted mainstream audiences charm romance mess around ever saw nasty surreal could ready watched developed taste got accustomed levels graphic injustice crooked guards sold nickel inmates kill order get away well mannered middle class turned bitches lack street skills experience may become comfortable uncomfortable viewing thats touch darker side\n",
            "Token IDs: tensor([[  101,  2028, 15814,  3855,  3666,  1015, 11472,  2792, 13322,  2157,\n",
            "          3599,  3047,  7987,  2034,  2518,  4930, 24083,  4895, 10258,  2378,\n",
            "          8450,  5019,  4808,  2275,  2773,  2175,  3404,  2265,  8143, 18627,\n",
            "          5199,  3593,  8005, 17957, 12362,  5850,  3348, 13076,  4438,  2224,\n",
            "          2170,  8367,  2445, 17411,  4555,  3036,  2110,  7279,  4221, 12380,\n",
            "          2854,  7679,  3701, 14110,  2103,  6388,  2930,  3827,  4442,  3221,\n",
            "         21430,  2227, 20546,   102]])\n",
            "Tokenized: [CLS] one reviewers mentioned watching 1 oz episode hooked right exactly happened br first thing struck brutality unflinching scenes violence set word go trust show faint hearted timid pulls punches regards drugs sex hardcore classic use called nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inward [SEP]\n",
            "Attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in inputs:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "print('Original: ', inputs[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Tokenized:', tokenizer.decode(input_ids[0][0]))\n",
        "print('Attention_mask', attention_masks[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX3RTonhxR1X"
      },
      "outputs": [],
      "source": [
        "# Creating tensors for input_ids and attention masks\n",
        "bert_input_ids = torch.cat(input_ids, dim=0)\n",
        "bert_attention_masks = torch.cat(attention_masks, dim=0)\n",
        "bert_labels = torch.tensor(labels)\n",
        "\n",
        "# Bert Input Features types\n",
        "print(type(bert_input_ids))\n",
        "print(type(bert_attention_masks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oETn4eBTsVSv"
      },
      "source": [
        "# Model definition, training, and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw2gGJklOwzB"
      },
      "source": [
        "### Sequence Classifacation Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_QI6u6a3B91",
        "outputId": "f7a5b84d-d425-4b9b-e8cd-dfc17c05df11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model and trying to train on GPU\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRvQndWl4GPs"
      },
      "source": [
        "### training test split data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use train_test_split to split our data into train and validations after alreadying having the bert input_ids and attention masks. Using this function to create DataLoaders to use the data sets for further processing.  "
      ],
      "metadata": {
        "id": "jWQ9JCoHNkzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q_hcXR5BlTfe"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def train_valid_split(input_ids, attention_masks, labels):\n",
        "  # Use 80% for training and 20% for validation.\n",
        "  train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                              random_state=2021, test_size=0.2)\n",
        "  # Do the same for the masks.\n",
        "  train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                              random_state=2021, test_size=0.2)\n",
        "\n",
        "  print('example train_input:', train_inputs[0])\n",
        "  print('example attention_mask', train_masks[0])\n",
        "  train_labels = torch.tensor(train_labels)\n",
        "  validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "  # Create the DataLoader for our training set.\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "  # Create the DataLoader for our validation set.\n",
        "  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "  validation_sampler = SequentialSampler(validation_data)\n",
        "  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "  return train_dataloader, validation_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "miGxF5IRlTfe",
        "outputId": "d3db91fb-67b2-40b9-9f47-f50d7f2c34d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example train_input: tensor([  101,  2471,  3585,  8201,  7842,  5737, 10649,  2466,  7987,  7814,\n",
            "         6463,  2614,  4289, 12991, 20857,  3689,  7315,  3370,  4125,  2991,\n",
            "         2637,  2034,  2931,  2694,  2739,  8133, 12347,  5896,  3257,  2488,\n",
            "         3459,  2453,  2979, 20327, 13109,  5714,  6508,  2428,  4276,  3947,\n",
            "         2204,  4516,  3395,  2190,  2126,  2175,  4050,  2844,  2537,  5300,\n",
            "         3185,  5450, 23105,  2214, 19857,  4246, 11973,   102,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "example attention_mask tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-f24dbceedb77>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_labels = torch.tensor(train_labels)\n",
            "<ipython-input-15-f24dbceedb77>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_labels = torch.tensor(validation_labels)\n"
          ]
        }
      ],
      "source": [
        "# Returning my two dataloaders\n",
        "bert_train_dataloader, bert_validation_dataloader = train_valid_split(bert_input_ids, bert_attention_masks, bert_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS8jveVN4Zqg"
      },
      "source": [
        "### Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating funtion to train model and capture training loops and loss calculations on multiple epochs."
      ],
      "metadata": {
        "id": "M82ZfVu7NEOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Nk_-DHjalTff"
      },
      "outputs": [],
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def train_model(model, epochs, train_dataloader, validation_dataloader):\n",
        "    optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8 )\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "    # defining lists of collected values\n",
        "    loss_values = []\n",
        "    eval_accs = []\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "        t0 = time.time()\n",
        "\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # This will return the loss (rather than the model output) because we\n",
        "            # have provided the `labels`.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "            # The call to `model` always returns a tuple, so we need to pull the\n",
        "            # loss value out of the tuple.\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value\n",
        "            # from the tensor.\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # Store the loss value for plotting the learning curve.\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "        model.eval()\n",
        "\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # batch = tuple(t for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # This will return the logits rather than the loss because we have\n",
        "                # not provided labels.\n",
        "                # token_type_ids is the same as the \"segment ids\", which\n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                outputs = model(b_input_ids,\n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=b_input_mask)\n",
        "\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            logits = outputs[0]\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            # Calculate the accuracy for this batch of test sentences.\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "            # Accumulate the total accuracy.\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            # Track the number of batches\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        avg_eval_acc = eval_accuracy/nb_eval_steps\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_eval_acc))\n",
        "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "        eval_accs.append(avg_eval_acc)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "    return loss_values, eval_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Jc1PU4PglTff",
        "outputId": "22fd1250-0647-4037-d7ba-1407d5ce50be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    625.    Elapsed: 0:00:28.\n",
            "  Batch    80  of    625.    Elapsed: 0:00:55.\n",
            "  Batch   120  of    625.    Elapsed: 0:01:21.\n",
            "  Batch   160  of    625.    Elapsed: 0:01:48.\n",
            "  Batch   200  of    625.    Elapsed: 0:02:15.\n",
            "  Batch   240  of    625.    Elapsed: 0:02:41.\n",
            "  Batch   280  of    625.    Elapsed: 0:03:08.\n",
            "  Batch   320  of    625.    Elapsed: 0:03:34.\n",
            "  Batch   360  of    625.    Elapsed: 0:04:01.\n",
            "  Batch   400  of    625.    Elapsed: 0:04:28.\n",
            "  Batch   440  of    625.    Elapsed: 0:04:55.\n",
            "  Batch   480  of    625.    Elapsed: 0:05:21.\n",
            "  Batch   520  of    625.    Elapsed: 0:05:48.\n",
            "  Batch   560  of    625.    Elapsed: 0:06:15.\n",
            "  Batch   600  of    625.    Elapsed: 0:06:41.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:06:58\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:00:34\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    625.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    625.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    625.    Elapsed: 0:01:20.\n",
            "  Batch   160  of    625.    Elapsed: 0:01:47.\n",
            "  Batch   200  of    625.    Elapsed: 0:02:14.\n",
            "  Batch   240  of    625.    Elapsed: 0:02:41.\n",
            "  Batch   280  of    625.    Elapsed: 0:03:08.\n",
            "  Batch   320  of    625.    Elapsed: 0:03:34.\n",
            "  Batch   360  of    625.    Elapsed: 0:04:01.\n",
            "  Batch   400  of    625.    Elapsed: 0:04:28.\n",
            "  Batch   440  of    625.    Elapsed: 0:04:55.\n",
            "  Batch   480  of    625.    Elapsed: 0:05:22.\n",
            "  Batch   520  of    625.    Elapsed: 0:05:49.\n",
            "  Batch   560  of    625.    Elapsed: 0:06:16.\n",
            "  Batch   600  of    625.    Elapsed: 0:06:43.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:07:00\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:00:34\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    625.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    625.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    625.    Elapsed: 0:01:20.\n",
            "  Batch   160  of    625.    Elapsed: 0:01:47.\n",
            "  Batch   200  of    625.    Elapsed: 0:02:14.\n",
            "  Batch   240  of    625.    Elapsed: 0:02:41.\n",
            "  Batch   280  of    625.    Elapsed: 0:03:07.\n",
            "  Batch   320  of    625.    Elapsed: 0:03:34.\n",
            "  Batch   360  of    625.    Elapsed: 0:04:01.\n",
            "  Batch   400  of    625.    Elapsed: 0:04:28.\n",
            "  Batch   440  of    625.    Elapsed: 0:04:55.\n",
            "  Batch   480  of    625.    Elapsed: 0:05:21.\n",
            "  Batch   520  of    625.    Elapsed: 0:05:49.\n",
            "  Batch   560  of    625.    Elapsed: 0:06:16.\n",
            "  Batch   600  of    625.    Elapsed: 0:06:42.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:06:59\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:00:34\n",
            "\n",
            "Training complete!\n",
            "[0.2524852383732796, 0.16065050712823867, 0.09810120258033275]\n",
            "[0.8618630573248408, 0.8672372611464968, 0.8690286624203821]\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "loss_values, eval_accs = train_model(model, epochs, bert_train_dataloader, bert_validation_dataloader)\n",
        "print(loss_values)\n",
        "print(eval_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing set using accuracy, precision, recall, and F1-score metrics"
      ],
      "metadata": {
        "id": "Ikg1VaVzNYTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tried to compute metrics using the Trainer Class and Trainer Arguments but was not able to compile and set up Trainer properly. If I would continue to do this, I learned this was the more proper way too late into the assignment.\n",
        "Parts to remember or implement is to use pipelines and Trainer in together to be able to create metrics dynamically."
      ],
      "metadata": {
        "id": "QKX4Eeq6B0B8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_-rrAQpsVSw"
      },
      "source": [
        "# Sample movie review predictions and explanations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was not able to get the syntax to properly work but my goal was to interate over a few examples of simple reviews and I was expecting to get a prediction of 1 or 0 to determine the sentiment."
      ],
      "metadata": {
        "id": "-NKNsietKwqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moQfdllyJJ99"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    'this is such an amazing movie!',  # this is the same sentence tried earlier\n",
        "    'The movie was great!',\n",
        "    'The movie was meh.',\n",
        "    'The movie was idiotic.',\n",
        "    'The movie was terrible...'\n",
        "]\n",
        "\n",
        "sample_predictions = []\n",
        "for batch in bert_validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch[i]\n",
        "\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels).logits\n",
        "    pred = torch.argmax(outputs, dim=1)\n",
        "    sample_predictions.append(pred)\n",
        "\n",
        "print(sample_predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}