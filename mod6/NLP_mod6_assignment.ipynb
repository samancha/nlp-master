{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup \n",
    "\n",
    "Installed needed libraries and dataset from Kaggle for this assignment.\n",
    "Imports are all located at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install only once\n",
    "# ! pip install kaggle\n",
    "# ! pip install -q --upgrade keras-nlp\n",
    "# ! pip install tensorflow --upgrade\n",
    "\n",
    "# Download the dataset from kaggle (kaggle api key required )\n",
    "# ! kaggle datasets download -d shashwatwork/consume-complaints-dataset-fo-nlp \n",
    "\n",
    "# unzip it\n",
    "# !tar -zxf consume-complaints-dataset-fo-nlp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (set_seed,\n",
    "                          TrainingArguments,\n",
    "                          Trainer,\n",
    "                          AdamW, \n",
    "                          get_linear_schedule_with_warmup,\n",
    "                          BertTokenizer, TFBertForSequenceClassification, InputExample, InputFeatures)\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# import keras_nlp\n",
    "# import keras_core as keras\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "# from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# Set seed for reproducibility.\n",
    "set_seed(58)\n",
    "\n",
    "# Look for gpu to use. Will use `cpu` by default if no gpu found.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "I found that the dataset did contain some null values and decided to remove those rows. I also found the the dataset was imbalanced which a majority of the products being credit_reporting. The length of the narratives also varied so i knew some padding and truncation would be needed when tokenizing the data. There was also an extra column that was just a copy of the index so i removed that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovery of null values: \n",
      "\n",
      " Unnamed: 0    0\n",
      "product       0\n",
      "narrative     0\n",
      "dtype: int64\n",
      "\n",
      "Distribution of products: \n",
      "\n",
      " product\n",
      "credit_reporting       91172\n",
      "debt_collection        23148\n",
      "mortgages_and_loans    18990\n",
      "credit_card            15566\n",
      "retail_banking         13535\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique product values: \n",
      " ['credit_card', 'retail_banking', 'credit_reporting', 'mortgages_and_loans', 'debt_collection']\n",
      "\n",
      "Narative sentence word count describe:\n",
      "  count    162411.000000\n",
      "mean         80.232798\n",
      "std         108.872213\n",
      "min           1.000000\n",
      "25%          27.000000\n",
      "50%          50.000000\n",
      "75%          95.000000\n",
      "max        2685.000000\n",
      "Name: narrative, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('complaints_processed.csv', index_col=False)\n",
    "# remove rows with null values\n",
    "df = df.dropna()\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "print(\"\\nPost removal of null values: \\n\\n\", df.isnull().sum())\n",
    "print(\"\\nDistribution of products: \\n\\n\", df['product'].value_counts())\n",
    "print(\"\\nUnique product values: \\n\\n\", df['product'].unique().tolist())\n",
    "print(\"\\nNarative sentence word count describe:\\n \", df['narrative'].apply(lambda x: len(str(x).split())).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My biggest struggle was determining which format to use for the labels. I decided to use the one hot encoding method, but went down two different routes. I learned that both routes work, but in the end you need an array of arrays (i.e. [[0,0,1,0,0],[0,1,0,0,0]... ]) coresponding with a 1 for the right feature it belongs to. \n",
    "\n",
    "In my second cell I define what my global variables are and split the data into train and test. I would want to continue and do a validate set as well, but for the sake of time i did not. From my EDA, I was able to determine that the mean was 80 words and 95 words for the 75%. I thought that by making my batch 128, I would be able to capture a lot of the narratives in one batch. I used 512 for max length because that's what the BERT model was trained on and I was going to add padding and trunction to account for the narratives that were not 512 words long.\n",
    "\n",
    "I approached the assignment by understanding the data types and reading on the different approaches between tensor and pytorch and which parts were similar in terms of conversion tools and training the models. So a big advantage in starting a project like this, is to create reusable code and quickly testing small portions, which is why I made a test_data and val_data which are just smaller subsets of _train and _test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "      <th>num_words</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>retail_banking</th>\n",
       "      <th>credit_reporting</th>\n",
       "      <th>mortgages_and_loans</th>\n",
       "      <th>debt_collection</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>purchase order day shipping amount receive pro...</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>forwarded message date tue subject please inve...</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retail_banking</td>\n",
       "      <td>forwarded message cc sent friday pdt subject f...</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report speciali...</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report made mis...</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product                                          narrative   \n",
       "0       credit_card  purchase order day shipping amount receive pro...  \\\n",
       "1       credit_card  forwarded message date tue subject please inve...   \n",
       "2    retail_banking  forwarded message cc sent friday pdt subject f...   \n",
       "3  credit_reporting  payment history missing credit report speciali...   \n",
       "4  credit_reporting  payment history missing credit report made mis...   \n",
       "\n",
       "   num_words  credit_card  retail_banking  credit_reporting   \n",
       "0        230            1               0                 0  \\\n",
       "1        132            1               0                 0   \n",
       "2        173            0               1                 0   \n",
       "3        131            0               0                 1   \n",
       "4        123            0               0                 1   \n",
       "\n",
       "   mortgages_and_loans  debt_collection  label  \n",
       "0                    0                0      0  \n",
       "1                    0                0      0  \n",
       "2                    0                0      1  \n",
       "3                    0                0      2  \n",
       "4                    0                0      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def label_to_int(label):\n",
    "    \"\"\" Convert label to int.\n",
    "    Returns: List of converted labels.\n",
    "    \"\"\"\n",
    "    global label_dict\n",
    "    label_dict = {'credit_card': 0, 'retail_banking': 1, 'credit_reporting': 2, 'mortgages_and_loans': 3, 'debt_collection': 4}  \n",
    "    # Convert labels to integers\n",
    "    return label_dict[label]\n",
    "\n",
    "# convert product to label as an integer (0-4)\n",
    "df['label'] = df['product'].apply(label_to_int)\n",
    "\n",
    "# calculate the number of words in each narrative\n",
    "# Notice that type in each row didn't defautl to string, so i had to convert to string prior to splitting\n",
    "df['num_words'] = df['narrative'].apply(lambda x: len(str(x).split(\" \")))\n",
    "product_labels = df['product'].unique().tolist()\n",
    "\n",
    "# create columns for each product label\n",
    "for label in product_labels:\n",
    "    df[label] = df['product'].apply(lambda x: 1 if x == label else 0)\n",
    "\n",
    "# create columns \n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing multiclasification labels\n",
    "label_vals = [0,1,2,3,4]\n",
    "labels = ['credit_card', 'retail_banking', 'credit_reporting', 'mortgages_and_loans', 'debt_collection']\n",
    "num_labels = len(labels)\n",
    "\n",
    "# create traing and test sets\n",
    "X = df['narrative'].values\n",
    "y = df[labels].values\n",
    "\n",
    "#  Batch size and the max length of the sequence\n",
    "batch_size = 128\n",
    "max_length = 512  \n",
    "\n",
    "# Use this to train the whole dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=58, stratify=y)\n",
    "\n",
    "# create smaller test and validation data to test flow with\n",
    "test_data = X_train[:10]\n",
    "test_labels = y_train[:10]\n",
    "print(test_labels)\n",
    "\n",
    "val_data = X_test[10:20]\n",
    "val_labels = y_test[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tokenization and conversion of input features\n",
    "\n",
    "I tested using the BERT-base-uncased because that's what I'm familiar with from the last assignment and I didn't fully get the last assignment to work. What I did do more purposely in this assignment is to use tensorflow and to use the appropriate TF SequenceClassification model for this tokenized data. I later noticed that distilBert also has a normal DistilBertTokenizer and TFDistilBertForSequenceClassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputExample(guid='0', text_a='please reference complaint retailed well fargo filing complaint agency please read email attached received well fargo today requesting information already provided asking house vacant instructed vacate premise well fargo counter offer house listed year ago countering offer settle bottom email said correspondence particular loan guideline outlined specific loan interpreted well fargo home mortgage loan blatant retaliation filing complaint cfpb asking assistance senator assistance email senator office attached well fargo stop', text_b=None, label=array([0, 0, 0, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# Converting test and validation data to InputExamples\n",
    "train_examples = [InputExample(guid=str(i), text_a=test_data[i], label=test_labels[i]) for i in range(len(test_data))]\n",
    "print(train_examples[0])\n",
    "\n",
    "test_examples = [InputExample(guid=str(i), text_a=val_data[i], label=val_labels[i]) for i in range(len(val_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I enjoyed using both InputExample and InputFeatures because it helped me understand the data types and how to convert them. I also learned that the input_ids are the input words encoded and the attention_mask is identification of where the enconding begin and end with the padding and truncation up to the max length. I also learned that the best approach was to have the labels are the one hot encoded labels at this point. This was a big paint point to get the data just right. By making it reusable I was able to test it on the smaller test_data and val_data sets, and can build on it in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert InputExamples to InputFeatures\n",
    "def convert_examples_to_features(examples, tokenizer, max_length=max_length):\n",
    "    features = []\n",
    "    for example in examples:\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            example.text_a,\n",
    "            add_special_tokens=True, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask = True,\n",
    "            # return_token_type_ids=True,\n",
    "            max_length=max_length, \n",
    "        )\n",
    "        features.append(InputFeatures(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], label=example.label))\n",
    "    return features\n",
    "\n",
    "train_features = convert_examples_to_features(train_examples, tokenizer, max_length=max_length)\n",
    "# print(\"train feature: \",train_features[0])\n",
    "# print(\"input ids: \",train_features[0].input_ids)\n",
    "# print(\"attention mask: \",train_features[0].attention_mask)\n",
    "\n",
    "test_features = convert_examples_to_features(test_examples, tokenizer, max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the final step to convert the features into the larger object of a tensor flow dataset. I was able to use the from_tensor_slices method to convert the features into a dataset. I also used the shuffle method to shuffle the data and the batch method to create the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert InputFeatures to TensorFlow datasets\n",
    "def convert_features_to_tf_dataset(features):\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_labels = []\n",
    "\n",
    "    for feature in features:\n",
    "        all_input_ids.append(feature.input_ids)\n",
    "        all_attention_masks.append(feature.attention_mask)\n",
    "        all_labels.append(feature.label)\n",
    "\n",
    "    # Convert lists to TF tensors\n",
    "    tf_ds = tf.data.Dataset.from_tensor_slices(({\"input_ids\": all_input_ids, \"attention_mask\": all_attention_masks}, all_labels))\n",
    "    return tf_ds\n",
    "\n",
    "train_dataset = convert_features_to_tf_dataset(train_features)\n",
    "batch_dataset = train_dataset.shuffle(10000).batch(5).repeat(2)\n",
    "\n",
    "test_dataset = convert_features_to_tf_dataset(test_features)\n",
    "batch_test_dataset = test_dataset.shuffle(10000).batch(5).repeat(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition, training, and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and intstantiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest part of the assignment was choosing a model you were comfortable with. Since I've never trained a model end to end, I wanted to look at some of the newer ways to do it, so I could reuse this pattern and potentially deploy the model. Tensor flow is also Keras friendly, and I knew that would help with getting metrics. I quickly learned I could keras could initialize the Adam optimizer and has some built in metrics that are easy to implement. Similar to a pipeline I would say, but there are probably some more advances ways of doing that. One configuration that I had to dig into was what from_logits was and why it was needed. I learned that it was needed because the model was not trained on the softmax function, so it needed to be added to the model. T\n",
    "\n",
    "he learning_rate of 5e-05 the learning rate for the model was used from hugging face documentation. I also learned that the loss function was categorical_crossentropy because the labels were one hot encoded. Balanced accuracy will take care of our average accuracy for all the classes. (balanced_accuracy). The thresholds needed to be 0 because the logits was true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05, epsilon=1e-08, clipnorm=1.0),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy('accuracy'),\n",
    "                       tf.keras.metrics.Recall(thresholds=0), \n",
    "                       tf.keras.metrics.Precision(thresholds=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "I was able to use fit the data to the model and use the validation data to see how the model was doing. I was able to get the accuracy and loss metrics, recall, and precision from the model. I noticed ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2/2 [==============================] - 61s 31s/step - loss: 1.8730 - accuracy: 0.4000 - recall_2: 0.4000 - precision: 0.3636\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 82s 41s/step - loss: 1.5632 - accuracy: 0.4000 - recall_2: 0.6000 - precision: 0.3529\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 53s 27s/step - loss: 1.4502 - accuracy: 0.4000 - recall_2: 0.7000 - precision: 0.3500\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(batch_dataset, epochs=3, verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_raw = model.predict(batch_test_dataset).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 3\n",
      "Sample Prediction [3 2 3 2 2 2 3 2 2 2]\n",
      "True values of Prediction range [2 2 3 3 3 2 2 2 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         1\n",
      "           1       1.00      0.00      0.00         1\n",
      "           2       0.43      0.60      0.50         5\n",
      "           3       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.69      0.23      0.21        10\n",
      "weighted avg       0.51      0.40      0.35        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = tf.nn.softmax(predicted_raw, axis=-1)\n",
    "y_predicted = tf.argmax(probs, axis=1).numpy()\n",
    "predicted_label = y_predicted[0]\n",
    "print(f\"Predicted label: {predicted_label}\")\n",
    "\n",
    "# Convert y_true to label-encoded format\n",
    "y_true = np.argmax(val_labels, axis=1)\n",
    "print(\"Sample Prediction\", y_predicted)\n",
    "print(\"True values of Prediction range\", y_true)\n",
    "print(classification_report(y_true, y_predicted, zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
