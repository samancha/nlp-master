{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install only once\n",
    "# ! pip install kaggle\n",
    "# ! pip install -q --upgrade keras-nlp\n",
    "! pip install tensorflow --upgrade\n",
    "\n",
    "\n",
    "\n",
    "# Download the dataset from kaggle\n",
    "# ! kaggle datasets download -d shashwatwork/consume-complaints-dataset-fo-nlp\n",
    "# unzip it\n",
    "# !tar -zxf consume-complaints-dataset-fo-nlp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (set_seed,\n",
    "                          TrainingArguments,\n",
    "                          Trainer,\n",
    "                          AdamW, \n",
    "                          get_linear_schedule_with_warmup,\n",
    "                          BertTokenizer, TFBertForSequenceClassification, InputExample, InputFeatures)\n",
    "\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# import keras_nlp\n",
    "# import keras_core as keras\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# Set seed for reproducibility.\n",
    "set_seed(58)\n",
    "\n",
    "# Look for gpu to use. Will use `cpu` by default if no gpu found.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovery of null values: \n",
      "\n",
      " Unnamed: 0    0\n",
      "product       0\n",
      "narrative     0\n",
      "dtype: int64\n",
      "\n",
      "Distribution of products: \n",
      "\n",
      " product\n",
      "credit_reporting       91172\n",
      "debt_collection        23148\n",
      "mortgages_and_loans    18990\n",
      "credit_card            15566\n",
      "retail_banking         13535\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique product values: \n",
      " ['credit_card', 'retail_banking', 'credit_reporting', 'mortgages_and_loans', 'debt_collection']\n",
      "\n",
      "Narative sentence word count describe:\n",
      "  count    162411.000000\n",
      "mean         80.232798\n",
      "std         108.872213\n",
      "min           1.000000\n",
      "25%          27.000000\n",
      "50%          50.000000\n",
      "75%          95.000000\n",
      "max        2685.000000\n",
      "Name: narrative, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('complaints_processed.csv', index_col=False)\n",
    "# remove rows with null values\n",
    "df = df.dropna()\n",
    "print(\"Discovery of null values: \\n\\n\", df.isnull().sum())\n",
    "print(\"\\nDistribution of products: \\n\\n\", df['product'].value_counts())\n",
    "print(\"\\nUnique product values: \\n\", df['product'].unique().tolist())\n",
    "print(\"\\nNarative sentence word count describe:\\n \", df['narrative'].apply(lambda x: len(str(x).split())).describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>narrative</th>\n",
       "      <th>num_words</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>retail_banking</th>\n",
       "      <th>credit_reporting</th>\n",
       "      <th>mortgages_and_loans</th>\n",
       "      <th>debt_collection</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>purchase order day shipping amount receive pro...</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit_card</td>\n",
       "      <td>forwarded message date tue subject please inve...</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retail_banking</td>\n",
       "      <td>forwarded message cc sent friday pdt subject f...</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report speciali...</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>credit_reporting</td>\n",
       "      <td>payment history missing credit report made mis...</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product                                          narrative   \n",
       "0       credit_card  purchase order day shipping amount receive pro...  \\\n",
       "1       credit_card  forwarded message date tue subject please inve...   \n",
       "2    retail_banking  forwarded message cc sent friday pdt subject f...   \n",
       "3  credit_reporting  payment history missing credit report speciali...   \n",
       "4  credit_reporting  payment history missing credit report made mis...   \n",
       "\n",
       "   num_words  credit_card  retail_banking  credit_reporting   \n",
       "0        230            1               0                 0  \\\n",
       "1        132            1               0                 0   \n",
       "2        173            0               1                 0   \n",
       "3        131            0               0                 1   \n",
       "4        123            0               0                 1   \n",
       "\n",
       "   mortgages_and_loans  debt_collection  label  \n",
       "0                    0                0      0  \n",
       "1                    0                0      0  \n",
       "2                    0                0      1  \n",
       "3                    0                0      2  \n",
       "4                    0                0      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\n",
    "def label_to_int(label):\n",
    "    \"\"\" Convert label to int.\n",
    "    Returns: List of converted labels.\n",
    "    \"\"\"\n",
    "    global label_dict\n",
    "    label_dict = {'credit_card': 0, 'retail_banking': 1, 'credit_reporting': 2, 'mortgages_and_loans': 3, 'debt_collection': 4}  \n",
    "    # Convert labels to integers\n",
    "    return label_dict[label]\n",
    "\n",
    "df['label'] = df['product'].apply(label_to_int)\n",
    "# calculate the number of words in each narrative\n",
    "# Notice that type in each row didn't defautl to string, so i had to convert to string prior to splitting\n",
    "df['num_words'] = df['narrative'].apply(lambda x: len(str(x).split(\" \")))\n",
    "product_labels = df['product'].unique().tolist()\n",
    "\n",
    "for label in product_labels:\n",
    "    df[label] = df['product'].apply(lambda x: 1 if x == label else 0)\n",
    "\n",
    "# create columns \n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advised get reverse mortgage one reverse mortgage funded original principal limit one lump sum could invest receive monthly income idea current principal limit could grow monthly interest plus service fee mip compounding monthly husband getting married living together home since since husband added name deed name still maiden name time lender told u spouse could mortgage age said worry added loan turn signed since turning attempting get help immediately called xxxxnd birthday knew important afraid something happened husband would leave home lived past year feel lender violated law loan process telling u never would signed otherwise counseled risk option lump sum etc predatory constantly calling u afterward nowhere found question reverse mortgage many company final contacted many time tried six year finally wish get resolved behind u happen called written enclosed original adviser went california left florida loan made home date contact plus many many telephone call large file information year trying get help particularly vulnerable suppose excuse trusted lender told u would terrible hardship leave home reverse mortgage may help case become year anguish regret constant worry sure understand married time signing may tell added later true beware taken advantage counseling recent call made time someone call back leaving extension telephone number tried calling back many time got response one reverse mortgage'\n",
      " 'authorize give consent pull credit affected score tremendously highly upset done without knowledge please remove credit report soon possible'\n",
      " 'recently found section state creditor continue report disputed unless proof contrary receive documentation proof request clarify company compliance also demand provide verification document reviewed otherwise delete account immediately'\n",
      " 'recognize account inquiry responsible debt except otherwise provided section consumer reporting agency shall block reporting information file consumer consumer identifies information resulted alleged identity theft later business day date receipt agency appropriate proof identity consumer copy identity theft report identification information consumer statement consumer information information relating transaction consumer b notification consumer reporting agency shall promptly notify furnisher information identified consumer subsection section information may result identity theft identity theft report filed block requested section effective date block c authority decline rescind general consumer reporting agency may decline block may rescind block information relating consumer section consumer reporting agency reasonably determines information blocked error block requested consumer error b information blocked block requested consumer basis material misrepresentation fact consumer relevant request block c consumer obtained possession good service money result blocked transaction transaction notification consumer block information declined rescinded subsection affected consumer shall notified promptly manner consumer notified reinsertion information section b title significance block purpose subsection consumer reporting agency rescinds block presence information file consumer prior blocking information evidence whether consumer knew known consumer obtained possession good service money result block exception resellers reseller file section shall apply consumer reporting agency consumer reporting agency reseller b time request consumer subsection section otherwise furnishing reselling consumer report concerning information identified consumer c informs consumer mean consumer may report identity theft bureau obtain consumer information regarding identity theft reseller file sole obligation consumer reporting agency section regard request consumer section shall block consumer report maintained consumer reporting agency subsequent use consumer accordance provision subsection section identifies consumer reporting agency information file consumer resulted identity theft b consumer reporting agency reseller identified information notice carrying obligation paragraph reseller shall promptly provide notice consumer decision block file notice shall contain name address telephone number consumer reporting agency consumer information obtained resale e exception verification company provision section apply check service company acting issue authorization purpose approving processing negotiable instrument electronic fund transfer similar method payment except beginning business day receipt information described paragraph subsection section check service company shall report national consumer reporting agency described section p title information identified subject identity theft report resulting identity theft f access blocked information law enforcement agency provision section shall construed requiring consumer reporting agency prevent federal state local law enforcement agency accessing blocked information consumer file agency could otherwise obtain access subchapter'\n",
      " 'loan amex always made payment time see always stellar payment record company tried contacting amex successful resolution definitely error part'\n",
      " 'credit inquiry unauthorized need removed credit report immediately'\n",
      " 'tried remove credit freeze experian creditor need information however process allows reasonable time place freeze immeidately online phone remove except mail state take day unacceptable online form security question ask submitting garbled answer cutoff impossible tell correct answer ironic verify identity log account access sensitive information blocking blocking credit freeze one reach phone email chat box order help situation repose get experian pay subscription damaging ability remain business get credit freeze lifted reasonable time someone help issue'\n",
      " 'account added created unbeknownst notice concern hold accountable accuse complicity exercise malevolent hereby mark likely might day view civil discord would plaintiff yet declare unjust claim met deliberate determined resistance counteraction clarity claim debt collection insufficient collection much le reporting must delete unjust injurious allegation significantly deficient requisite certified reporting compliance perfect format reporting testimonial evidence physically verifiable proof validation related full truth accuracy completeness timeliness ownership identity true debtor date balance audit calculation source code creditor collection code statement associated trailing fragment minimal portioned personal identifier pay status required confirmation collection elsewise standard mandatory proper reporting mentioned although checking addressing missing deficient aspect reporting compliance contesting debt compliant nature make aware since unlawful reporting transition collection equally complaint circumstance still yet validated document fact compliance requisite standard announced yet legally knowledge validity alleged claim delinquency derogatory nature certifiably compliant matter either collection attempt reporting despite previous consumer filed composed complaint checking might known especially shall elect take matter civil court debt derogatory claim must pursued particularly collection defined precisely compliant physically verifiable certifiable manner detailed requisite obeyed federal state collection reporting regulation associated noted said claim include limited fcra privacy rule fdcpa tcpa etc additionally entity act collector also elect act reporting party consumer credit must well adhere every single even regulatory reporting requisite standard reporting legal standing full accordance law accepted reporting standard date plaintiff failed demonstrate capacity willingness validate alleged debt much le certify fair accurate complete compliant reporting claim particularly significantly deficient display certified compliance given fact recent breach information collection repository hesitating readily accept presented without testimonial certified physically verifiable document evidence claim legitimate deny nothing yet reserve right question unproven claim accept statement claim plaintiff call court reject claim untrue unverified incomplete compliant otherwise invalid thereby dischargeable requirement dismissed full demand said court resolution today even full accord regulatory statute mentioned date received knowledge ever entering contractual relationship plaintiff forward civil complaint entity allegedly issued defaulted line credit accusation similar despite repeated call accuser demonstrate requisite presented physically verifiable document proof adequately acquired permissible purpose exactly individual irrefutably identified acknowledgement relationship party mentioned form knowledge ever knowingly acknowledging even unknowingly owe proven compliantly reported debt much le claim unproven debt alleged written declaration checking validity claim also document proof certifiable testimony factual complete compliance standard law even mandatory format compliance obvious allegation filed accuser plaintiff clear subterfuge act willful disregard ethical practice done ignorance requisite ethical regulatory compliant behavior accusation collection effort credit reporting claim vile nature derelict unjustly injurious unlawful doubt call dismissal statement claim discharge misreported delinquency derogatory behavior accuser complaint undeniably unfairly lodged versus knowledge ever receiving proven document fact statement account account aspect item alleged debt delinquent action reiterate called accuser present document certifiably true correct complete adequately compliant documentation full validation claim right collect alleged claim right report alleged claim let true compliance regulatory requisite mandatory optional plaintiff claim mute legal standing full accordance law must dismissed knowledge ever entering open account plaintiff entity allegedly issued defaulted line credit derogatory claim credit fact claim even submitted adequate compliant proof genesis relationship inability prove application permissible purpose said alleged application agreement contract describing relationship related alleged claim account debt otherwise derelict documentation claim inherently make invalid plaintiff whole statement claim summons complaint request court resolve adequately compliantly required immediate eradication complaint charge rectification injurious collection reporting practice compliance appropriate collection practice equally compliance appropriate complete reporting practice mandatory optional stand complaining plaintiff unjustly unethically likely illegally absolute deficiency requisite legal standing full accordance applicable law mentioned collection practice well reporting practice particularly inability unwillingness timely fully certify physically verifiable document proof full validity debt claim compliance reporting even mandatory format declare right preference stand claim plaintiff call authority integrity ensure truth claim correctness claim completeness claim ownership responsibility debt delinquency debt alleged noted claim perfect compliance collection action related claim compliance reporting action related claim'\n",
      " 'deposited two check one check dollar another dollar check perfectly good account good standing dollar immediately available le cash transaction dollar going business next day tried get fuel vehicle gas station transaction declined evacuated due california coping family tragedy dealing government shutdown due unable get fuel vehicle due chase bank blocking fund called chase time trying find going fraud department bank apparently blocked account unknown reason operator chase idea went branch oregon deposited check banker idea problem bank manager called offered assist called back tried get help thing managed get entire account shut also rude refused inform problem chance bank informed problem one point banker told check writer go branch present two form id shocked bizarre demand laughed told bank return check return check check writer return check check drawn one xxxxhase bank took fund equalling dollar check writer received check back received fund chase bank refuse inform u problem informed evacuated due wildfire california sending bizarre message location evacuated even though repeatedly informed send mail send mail po box address physical address fraud department chase bank harassed u repeatedly past personal banker opened chase bank account resigned bank due harassment fraud department run thug bank never informed anything wrong deposit day passed fund cleared ten day earlier blocked account writing check money account visited check writer discussed manager said chase bank fact taken fund check writer outraged also file complaint chase stealing money account giving chase bank stole money stole money stole money check writer chase bank fraud department clearly run thug criminal chase bank return money go district attorney file another complaint filed two complaint chase refuse respond outrage unable pay business expense received eviction notice money office need'\n",
      " 'request free annual credit report believe consumer reporting agency invalidated true spirit fair accurate credit transaction act act first established intended establish plan whereas common american citizen could obtain copy credit report least year free charge since credit reporting agency marketing division automation system obtain free annual report looped information request steer citizen additional product offer excessive unnecessary even though may received approval updated credit report either equifax respectively unfair need mail request since submit personal information consumer financial protection bureau cfpb portal believe since cfpb sole responsible oversight party fair credit reporting act imperative additional solicitation information credit bureau blocked permanently along citizen receive free credit report upon request credit reporting agency important aspect national banking system properly function current aggressive marketing campaign soliciting citizen arbitrary fico score gone far including limited must return common ground fair consumer united state must able request additional marketing term accordingly making request free credit report confirmation number attached email address thank']\n",
      "[[0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "label_vals = [0,1,2,3,4]\n",
    "labels = ['credit_card', 'retail_banking', 'credit_reporting', 'mortgages_and_loans', 'debt_collection']\n",
    "num_labels = len(labels)\n",
    "\n",
    "# create traing and test sets\n",
    "X = df['narrative'].values\n",
    "# y = df['label'].values\n",
    "y = df[labels].values\n",
    "\n",
    "batch_size = 128\n",
    "# Choose a max_length that suits your data\n",
    "max_length = 512  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=58)\n",
    "\n",
    "# create 5 rows of data to test the model\n",
    "test_data = X_test[:10]\n",
    "test_labels = y_test[:10]\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tokenization and conversion of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputExample(guid='0', text_a='advised get reverse mortgage one reverse mortgage funded original principal limit one lump sum could invest receive monthly income idea current principal limit could grow monthly interest plus service fee mip compounding monthly husband getting married living together home since since husband added name deed name still maiden name time lender told u spouse could mortgage age said worry added loan turn signed since turning attempting get help immediately called xxxxnd birthday knew important afraid something happened husband would leave home lived past year feel lender violated law loan process telling u never would signed otherwise counseled risk option lump sum etc predatory constantly calling u afterward nowhere found question reverse mortgage many company final contacted many time tried six year finally wish get resolved behind u happen called written enclosed original adviser went california left florida loan made home date contact plus many many telephone call large file information year trying get help particularly vulnerable suppose excuse trusted lender told u would terrible hardship leave home reverse mortgage may help case become year anguish regret constant worry sure understand married time signing may tell added later true beware taken advantage counseling recent call made time someone call back leaving extension telephone number tried calling back many time got response one reverse mortgage', text_b=None, label=array([0, 0, 0, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "# Convert texts to InputExamples\n",
    "train_examples = [InputExample(guid=str(i), text_a=test_data[i], label=test_labels[i]) for i in range(len(test_data))]\n",
    "\n",
    "print(train_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train feature:  InputFeatures(input_ids=[101, 9449, 2131, 7901, 14344, 2028, 7901, 14344, 6787, 2434, 4054, 5787, 2028, 15116, 7680, 2071, 15697, 4374, 7058, 3318, 2801, 2783, 4054, 5787, 2071, 4982, 7058, 3037, 4606, 2326, 7408, 2771, 2361, 7328, 2075, 7058, 3129, 2893, 2496, 2542, 2362, 2188, 2144, 2144, 3129, 2794, 2171, 15046, 2171, 2145, 10494, 2171, 2051, 18496, 2121, 2409, 1057, 18591, 2071, 14344, 2287, 2056, 4737, 2794, 5414, 2735, 2772, 2144, 3810, 7161, 2131, 2393, 3202, 2170, 22038, 20348, 4859, 5798, 2354, 2590, 4452, 2242, 3047, 3129, 2052, 2681, 2188, 2973, 2627, 2095, 2514, 18496, 2121, 14424, 2375, 5414, 2832, 4129, 1057, 2196, 2052, 2772, 4728, 9517, 2098, 3891, 5724, 15116, 7680, 4385, 21659, 7887, 4214, 1057, 9707, 7880, 2179, 3160, 7901, 14344, 2116, 2194, 2345, 11925, 2116, 2051, 2699, 2416, 2095, 2633, 4299, 2131, 10395, 2369, 1057, 4148, 2170, 2517, 10837, 2434, 11747, 2253, 2662, 2187, 3516, 5414, 2081, 2188, 3058, 3967, 4606, 2116, 2116, 7026, 2655, 2312, 5371, 2592, 2095, 2667, 2131, 2393, 3391, 8211, 6814, 8016, 9480, 18496, 2121, 2409, 1057, 2052, 6659, 26479, 2681, 2188, 7901, 14344, 2089, 2393, 2553, 2468, 2095, 21782, 9038, 5377, 4737, 2469, 3305, 2496, 2051, 6608, 2089, 2425, 2794, 2101, 2995, 2022, 8059, 2579, 5056, 17041, 3522, 2655, 2081, 2051, 2619, 2655, 2067, 2975, 5331, 7026, 2193, 2699, 4214, 2067, 2116, 2051, 2288, 3433, 2028, 7901, 14344, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=array([0, 0, 0, 1, 0]))\n",
      "input ids:  [101, 9449, 2131, 7901, 14344, 2028, 7901, 14344, 6787, 2434, 4054, 5787, 2028, 15116, 7680, 2071, 15697, 4374, 7058, 3318, 2801, 2783, 4054, 5787, 2071, 4982, 7058, 3037, 4606, 2326, 7408, 2771, 2361, 7328, 2075, 7058, 3129, 2893, 2496, 2542, 2362, 2188, 2144, 2144, 3129, 2794, 2171, 15046, 2171, 2145, 10494, 2171, 2051, 18496, 2121, 2409, 1057, 18591, 2071, 14344, 2287, 2056, 4737, 2794, 5414, 2735, 2772, 2144, 3810, 7161, 2131, 2393, 3202, 2170, 22038, 20348, 4859, 5798, 2354, 2590, 4452, 2242, 3047, 3129, 2052, 2681, 2188, 2973, 2627, 2095, 2514, 18496, 2121, 14424, 2375, 5414, 2832, 4129, 1057, 2196, 2052, 2772, 4728, 9517, 2098, 3891, 5724, 15116, 7680, 4385, 21659, 7887, 4214, 1057, 9707, 7880, 2179, 3160, 7901, 14344, 2116, 2194, 2345, 11925, 2116, 2051, 2699, 2416, 2095, 2633, 4299, 2131, 10395, 2369, 1057, 4148, 2170, 2517, 10837, 2434, 11747, 2253, 2662, 2187, 3516, 5414, 2081, 2188, 3058, 3967, 4606, 2116, 2116, 7026, 2655, 2312, 5371, 2592, 2095, 2667, 2131, 2393, 3391, 8211, 6814, 8016, 9480, 18496, 2121, 2409, 1057, 2052, 6659, 26479, 2681, 2188, 7901, 14344, 2089, 2393, 2553, 2468, 2095, 21782, 9038, 5377, 4737, 2469, 3305, 2496, 2051, 6608, 2089, 2425, 2794, 2101, 2995, 2022, 8059, 2579, 5056, 17041, 3522, 2655, 2081, 2051, 2619, 2655, 2067, 2975, 5331, 7026, 2193, 2699, 4214, 2067, 2116, 2051, 2288, 3433, 2028, 7901, 14344, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert InputExamples to InputFeatures\n",
    "def convert_examples_to_features(examples, tokenizer, max_length=max_length, label_list=labels, output_mode=\"classification\"):\n",
    "    features = []\n",
    "    for example in examples:\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            example.text_a,\n",
    "            add_special_tokens=True, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids=True,\n",
    "            max_length=max_length, \n",
    "        )\n",
    "        features.append(InputFeatures(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], label=example.label))\n",
    "    return features\n",
    "\n",
    "train_features = convert_examples_to_features(train_examples, tokenizer, max_length=max_length, label_list=test_labels)\n",
    "print(\"train feature: \",train_features[0])\n",
    "print(\"input ids: \",train_features[0].input_ids)\n",
    "print(\"attention mask: \",train_features[0].attention_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset'>\n",
      "<_TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(5,), dtype=tf.int64, name=None))>\n",
      "<class 'tensorflow.python.data.ops.batch_op._BatchDataset'>\n",
      "<_BatchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Convert InputFeatures to TensorFlow datasets\n",
    "def convert_features_to_tf_dataset(features):\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_labels = []\n",
    "\n",
    "    for feature in features:\n",
    "        all_input_ids.append(feature.input_ids)\n",
    "        all_attention_masks.append(feature.attention_mask)\n",
    "        all_labels.append(feature.label)\n",
    "\n",
    "    # Convert lists to TF tensors\n",
    "    tf_ds = tf.data.Dataset.from_tensor_slices(({\"input_ids\": all_input_ids, \"attention_mask\": all_attention_masks}, all_labels))\n",
    "    return tf_ds\n",
    "\n",
    "train_dataset = convert_features_to_tf_dataset(train_features)\n",
    "print(type(train_dataset))\n",
    "print(train_dataset)\n",
    "\n",
    "batch_dataset = train_dataset.shuffle(10000).batch(3)\n",
    "print(type(batch_dataset))\n",
    "print(batch_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition, training, and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and intstantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05, epsilon=1e-08, clipnorm=1.0),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy('accuracy'),\n",
    "                       tf.keras.metrics.Recall(thresholds=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 101s 13s/step - loss: 1.3454 - accuracy: 0.5000 - recall: 0.9000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 73s 18s/step - loss: 1.0108 - accuracy: 0.8000 - recall: 0.8000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 80s 19s/step - loss: 0.7613 - accuracy: 0.8000 - recall: 0.9000\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(batch_dataset, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_455 (Dropout)       multiple                  0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " classifier (Dense)          multiple                  3845      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109486085 (417.66 MB)\n",
      "Trainable params: 109486085 (417.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_raw = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer parameters\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "    # print(classification_report(y_test,nb.predict(X_test)))\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 2\n"
     ]
    }
   ],
   "source": [
    "test_sentence = test_data[4]\n",
    "test_input = tokenizer.encode_plus(test_sentence, add_special_tokens=True, return_tensors=\"tf\")\n",
    "outputs = model(test_input[\"input_ids\"], attention_mask=test_input[\"attention_mask\"])\n",
    "probs = tf.nn.softmax(outputs[0], axis=-1)\n",
    "predicted_label = tf.argmax(probs, axis=1).numpy()[0]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
